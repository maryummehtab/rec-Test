{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVj4SseSvk9z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00lmbBEprYQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIa1NqpZrZrN",
        "outputId": "714c7c1e-4985-4597-cb0e-ae1eee552a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0umExCbv6ed"
      },
      "outputs": [],
      "source": [
        "rating_dataset = pd.read_csv('/content/drive/MyDrive/Research/RAT (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rRlA4Dku_j2"
      },
      "outputs": [],
      "source": [
        "# Read the dataset from CSV\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Research/V-15.0 (1).csv', sep=',', encoding='latin-1')\n",
        "\n",
        "# Split the 'genres' column into multiple columns\n",
        "genre_columns = dataset['genres'].str.get_dummies('|')\n",
        "\n",
        "# Concatenate the original dataset with the genre columns\n",
        "dataset = pd.concat([dataset, genre_columns], axis=1)\n",
        "\n",
        "# Remove the original 'genres' column\n",
        "dataset.drop('genres', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM0N1TpRv6b_",
        "outputId": "dd3566f8-c266-4e49-d834-783395481d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                 title  \\\n",
              "0        1             Toy Story   \n",
              "1        2               Jumanji   \n",
              "2        3      Grumpier Old Men   \n",
              "3        4        Waiting Exhale   \n",
              "4        5  Father Bride Part II   \n",
              "\n",
              "                                            Overview  \n",
              "0  A cowboy doll is profoundly threatened and jea...  \n",
              "1  When two kids find and play a magical board ga...  \n",
              "2  John and Max resolve to save their beloved bai...  \n",
              "3  Based on Terry McMillan's novel, this film fol...  \n",
              "4  George Banks must deal not only with his daugh...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-2d5cd224-ee2f-4e44-b7b5-a93b36aaccfd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>Overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>A cowboy doll is profoundly threatened and jea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>When two kids find and play a magical board ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>John and Max resolve to save their beloved bai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting Exhale</td>\n",
              "      <td>Based on Terry McMillan's novel, this film fol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father Bride Part II</td>\n",
              "      <td>George Banks must deal not only with his daugh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d5cd224-ee2f-4e44-b7b5-a93b36aaccfd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-70e15b7f-4a59-4c0e-a9c6-18b24e43e89e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70e15b7f-4a59-4c0e-a9c6-18b24e43e89e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-70e15b7f-4a59-4c0e-a9c6-18b24e43e89e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d5cd224-ee2f-4e44-b7b5-a93b36aaccfd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d5cd224-ee2f-4e44-b7b5-a93b36aaccfd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "movie_dataset = dataset[['movieId','title', 'Overview']]\n",
        "movie_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ksMProEv6Ze"
      },
      "outputs": [],
      "source": [
        "merged_dataset = pd.merge(rating_dataset, movie_dataset, how='inner', on='movieId')\n",
        "merged_dataset.head()\n",
        "merged_dataset.to_csv('MDB.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajAS6hBHwMEE"
      },
      "source": [
        "### **User-Item matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jhb40YAUojp"
      },
      "outputs": [],
      "source": [
        "# Extract unique users and movies from the datasetum\n",
        "users = merged_dataset['userId'].unique()\n",
        "movies = merged_dataset['title'].unique()\n",
        "\n",
        "# Create the user-movie rating matrix\n",
        "UMR_matrix = np.zeros((len(users), len(movies)))\n",
        "\n",
        "# Group the data by user and movie\n",
        "grouped_data = merged_dataset.groupby(['userId', 'title'])\n",
        "\n",
        "# Fill the UMR_matrix with ratings\n",
        "for i, user in enumerate(users):\n",
        "    for j, movie in enumerate(movies):\n",
        "        try:\n",
        "            rating = grouped_data.get_group((user, movie))['rating'].values[0]\n",
        "            UMR_matrix[i][j] = rating\n",
        "        except KeyError:\n",
        "            UMR_matrix[i][j] = 0\n",
        "\n",
        "selected_users = [614, 615, 611, 613, 9, 612, 61, 167, 215, 605]\n",
        "selected_movies = ['Matrix', 'Lord Rings: Fellowship Ring', 'Lord Rings: Return King', 'Inception', 'Dark Knight',\n",
        "          'Iron Man 3', 'Guardians Galaxy', 'Black Panther', 'Guardians Galaxy 2', 'Tomb Raider']\n",
        "\n",
        "# Create a dictionary to map user indices to their respective formatted IDs\n",
        "formatted_ids = {f\"U{i+1}\": user_id for i, user_id in enumerate(selected_users)}\n",
        "\n",
        "# Calculate the maximum width of user IDs\n",
        "max_user_width = max(len(formatted_id) for formatted_id in formatted_ids.keys())\n",
        "\n",
        "# Create a dictionary to map movie indices to their respective formatted titles\n",
        "formatted_titles = {f\"M{i+1}\": movie_title for i, movie_title in enumerate(selected_movies)}\n",
        "\n",
        "# Calculate the maximum width of movie titles\n",
        "max_movie_width = max(len(formatted_title) for formatted_title in formatted_titles.keys())\n",
        "\n",
        "# Display the selected movies and users with their ratings\n",
        "print(\"\\nSelected Ratings:\")\n",
        "header = \" \"\n",
        "for movie_index in range(1, len(selected_movies) + 1):\n",
        "    movie_key = f\"M{movie_index}\"\n",
        "    header += f\"{movie_key:{max_movie_width}}\\t\"\n",
        "print(f\"{'':{max_user_width}}\\t{header}\")\n",
        "\n",
        "for user_index in range(1, len(selected_users) + 1):\n",
        "    user_key = f\"U{user_index}\"\n",
        "    user_id = formatted_ids.get(user_key, \"\")\n",
        "    row_data = f\"{user_key:{max_user_width}}\\t\"\n",
        "    for movie_index in range(1, len(selected_movies) + 1):\n",
        "        movie_key = f\"M{movie_index}\"\n",
        "        movie_title = formatted_titles.get(movie_key, \"\")\n",
        "        user_ratings = merged_dataset.loc[(merged_dataset['userId'] == user_id) & (merged_dataset['title'] == movie_title)]\n",
        "        rating = user_ratings['rating'].values[0] if len(user_ratings) > 0 else 0\n",
        "        row_data += f\"{rating:{max_movie_width}.1f}\\t\"\n",
        "    print(row_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egP93bBdwZLU"
      },
      "source": [
        "### **SVD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQycqT4cc34C"
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import svd\n",
        "\n",
        "# Load the user-item matrix\n",
        "# Assuming you already have the UMR_matrix from Algorithm 1\n",
        "\n",
        "# Add zero values to missing ratings in the user-item matrix\n",
        "UMR_matrix_filled = np.nan_to_num(UMR_matrix)\n",
        "\n",
        "# Set dimension k = 20 for matrix reduction\n",
        "k = 20\n",
        "\n",
        "# Calculate matrices U, Sigma, and V^T using SVD\n",
        "U, Sigma, VT = svd(UMR_matrix_filled)\n",
        "\n",
        "# Reduce matrices U, Sigma, and VT to dimension k\n",
        "U_reduced = U[:, :k]\n",
        "Sigma_reduced = np.diag(Sigma[:k])\n",
        "VT_reduced = VT[:k, :]\n",
        "\n",
        "# Calculate the predicted evaluation matrix\n",
        "predicted_matrix = np.dot(np.dot(U_reduced, Sigma_reduced), VT_reduced)\n",
        "\n",
        "# Display the predicted evaluation matrix\n",
        "#print(\"Predicted Evaluation Matrix:\")\n",
        "#for row in predicted_matrix:\n",
        "#    print(row)\n",
        "\n",
        "# Display the predicted evaluation matrix for selected users and movie titles\n",
        "selected_users = [614, 615, 611, 613, 9, 612, 61, 167, 215, 605]\n",
        "selected_movies = ['Matrix', 'Lord Rings: Fellowship Ring', 'Lord Rings: Return King', 'Inception', 'Dark Knight',\n",
        "          'Iron Man 3', 'Guardians Galaxy', 'Black Panther', 'Guardians Galaxy 2', 'Lara Croft: Tomb Raider']\n",
        "\n",
        "# Create a dictionary to map user indices to their respective formatted IDs\n",
        "formatted_ids = {f\"U{i+1}\": user_id for i, user_id in enumerate(selected_users)}\n",
        "\n",
        "# Calculate the maximum width of user IDs\n",
        "max_user_width = max(len(formatted_id) for formatted_id in formatted_ids.keys())\n",
        "\n",
        "# Create a dictionary to map movie indices to their respective formatted titles\n",
        "formatted_titles = {f\"M{i+1}\": movie_title for i, movie_title in enumerate(selected_movies)}\n",
        "\n",
        "# Calculate the maximum width of movie titles\n",
        "max_movie_width = max(len(formatted_title) for formatted_title in formatted_titles.keys())\n",
        "\n",
        "# Display the selected users and movie titles with their predicted ratings\n",
        "print(\"\\nPredicted Ratings:\")\n",
        "header = \"\"\n",
        "for movie_index in range(1, len(selected_movies) + 1):\n",
        "    movie_key = f\"M{movie_index}\"\n",
        "    header += f\"{movie_key:{max_movie_width}}\\t\"\n",
        "print(f\"{'':{max_user_width}}\\t{header}\")\n",
        "\n",
        "for user_index in range(1, len(selected_users) + 1):\n",
        "    user_key = f\"U{user_index}\"\n",
        "    user_id = formatted_ids.get(user_key, \"\")\n",
        "    row_data = f\"{user_key:{max_user_width}}\\t\"\n",
        "    for movie_index in range(1, len(selected_movies) + 1):\n",
        "        movie_key = f\"M{movie_index}\"\n",
        "        movie_title = formatted_titles.get(movie_key, \"\")\n",
        "        movie_index = np.where(movies == movie_title)[0][0]\n",
        "        predicted_rating = predicted_matrix[user_id - 1][movie_index]\n",
        "        row_data += f\"{predicted_rating:{max_movie_width}.1f}\\t\"\n",
        "    print(row_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzp2s1jZv6Wv"
      },
      "outputs": [],
      "source": [
        "genre_dataset= dataset[['movieId','Action', 'Adventure',\n",
        "       'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
        "       'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery',\n",
        "       'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']]\n",
        "genre_merged=pd.merge(merged_dataset, genre_dataset, how='inner', on='movieId')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVArAp4JwkAc"
      },
      "source": [
        "#### **FAV and UNPOPULAR GENRE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pla94RUW_XVz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a dataset dataframe 'genre_merged' containing movie ratings with separate genre columns\n",
        "\n",
        "# Get the unique genres from the dataset\n",
        "genres = genre_merged[['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']]\n",
        "\n",
        "# Iterate over each user\n",
        "for user_id in genre_merged['userId'].unique():\n",
        "    # Get the ratings given by the user\n",
        "    user_ratings = genre_merged.loc[genre_merged['userId'] == user_id, 'rating']\n",
        "\n",
        "    # Calculate the average rating for each genre\n",
        "    genre_ratings = []\n",
        "    for genre in genres.columns:\n",
        "        genre_ratings.append(np.mean(user_ratings[genres[genre] == 1]))\n",
        "\n",
        "    # Sort the genres based on average ratings\n",
        "    sorted_genres = sorted(zip(genres.columns, genre_ratings), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select the top 3 favorite genres\n",
        "    favorite_genres = [genre for genre, rating in sorted_genres[:3]]\n",
        "\n",
        "    # Select the bottom 3 unpopular genres\n",
        "    unpopular_genres = [genre for genre, rating in sorted_genres[-3:]]\n",
        "\n",
        "    print(f\"User ID: {user_id}\")\n",
        "    print(\"Favorite Genres:\", favorite_genres)\n",
        "    print(\"Unpopular Genres:\", unpopular_genres)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mioa9mXO_0IJ"
      },
      "outputs": [],
      "source": [
        "# Select a user to print their results\n",
        "selected_user_id = 614\n",
        "\n",
        "# Get the favorite and unpopular genres for the selected user\n",
        "selected_user_ratings = genre_merged.loc[genre_merged['userId'] == selected_user_id, 'rating']\n",
        "selected_user_genre_ratings = []\n",
        "for genre in genres.columns:\n",
        "    selected_user_genre_ratings.append(np.mean(selected_user_ratings[genres[genre] == 1]))\n",
        "selected_user_sorted_genres = sorted(zip(genres.columns, selected_user_genre_ratings), key=lambda x: x[1], reverse=True)\n",
        "selected_user_favorite_genres = [genre for genre, rating in selected_user_sorted_genres[:3]]\n",
        "selected_user_unpopular_genres = [genre for genre, rating in selected_user_sorted_genres[-3:]]\n",
        "\n",
        "# Print the results for the selected user\n",
        "print(f\"Selected User ID: {selected_user_id}\")\n",
        "print(\"Favorite Genres:\", selected_user_favorite_genres)\n",
        "print(\"Unpopular Genres:\", selected_user_unpopular_genres)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh3PC0nxws7z"
      },
      "source": [
        "#### **Highest predicted evaluation for users**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBjZbM-WAHew"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a predicted evaluation matrix 'predicted_ratings' and a dataframe 'genre_merged' containing movie ratings and genres\n",
        "\n",
        "# Create an empty list to store the recommended movies for all users\n",
        "all_users_movies = []\n",
        "\n",
        "# Iterate over each user\n",
        "for user_id in genre_merged['userId'].unique():\n",
        "    # Select the row of predicted evaluations for the user\n",
        "    user_predicted_ratings = predicted_matrix[user_id - 1]\n",
        "\n",
        "    # Get the movies that the user has not rated yet\n",
        "    unrated_movies = genre_merged[~genre_merged['movieId'].isin(genre_merged[genre_merged['userId'] == user_id]['movieId'].unique())]\n",
        "\n",
        "    # Create a new dataframe with unrated movies and their predicted ratings\n",
        "    unrated_movies_with_ratings = unrated_movies.merge(pd.DataFrame({'predicted_rating': user_predicted_ratings}), left_on='movieId', right_index=True)\n",
        "\n",
        "    # Remove duplicate movies (if any)\n",
        "    unrated_movies_with_ratings = unrated_movies_with_ratings.drop_duplicates(subset=['movieId'])\n",
        "\n",
        "    # Sort the unrated movies based on the predicted ratings in descending order\n",
        "    sorted_movies = unrated_movies_with_ratings.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "    # Prepare the table data\n",
        "    table_data = []\n",
        "    for _, row in sorted_movies.iterrows():\n",
        "        movie_id = row['movieId']\n",
        "        movie_title = row['title']\n",
        "        Over_view=row['Overview']\n",
        "        predicted_rating = row['predicted_rating']\n",
        "        table_data.append([user_id, movie_id, movie_title, predicted_rating,Over_view ])\n",
        "\n",
        "    # Create a DataFrame and format the columns\n",
        "    table_columns = ['userId', 'Movie ID', 'title', 'Predicted Rating', 'Overview']\n",
        "\n",
        "    # Fetch top recommended movies (first 25)\n",
        "    top_movies = table_data[:25]\n",
        "\n",
        "    table_df = pd.DataFrame(top_movies, columns=table_columns)\n",
        "\n",
        "    # Remove duplicate movies\n",
        "    unique_movies = table_df.drop_duplicates(subset=['Movie ID'])\n",
        "\n",
        "    # Add the unique recommended movies for the current user to the list\n",
        "    all_users_movies.append(unique_movies)\n",
        "\n",
        "# Print the recommended movies for all users\n",
        "for i, user_movies in enumerate(all_users_movies):\n",
        "    user_id = genre_merged['userId'].unique()[i]\n",
        "    print(f\"Recommended movies for User ID {user_id}:\")\n",
        "    print(user_movies.to_string(index=False))\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab5fPUlBBXE0"
      },
      "outputs": [],
      "source": [
        "# Find the index of the selected user in the list\n",
        "selected_user_index = genre_merged['userId'].unique().tolist().index(selected_user_id)\n",
        "\n",
        "# Check if the selected user exists in the list\n",
        "if selected_user_index != -1:\n",
        "    # Get the recommended movies for the selected user\n",
        "    selected_user_movies = all_users_movies[selected_user_index]\n",
        "\n",
        "    # Print the recommended movies for the selected user\n",
        "    print(f\"Recommended movies for User ID {selected_user_id}:\")\n",
        "    print(selected_user_movies.to_string(index=False))\n",
        "else:\n",
        "    print(f\"No recommended movies found for User ID {selected_user_id}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoIlHYLPw3dz"
      },
      "source": [
        "#### **MOVIES WITHOUT UNPOPULAR GENRE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abFu6A1mH8Rq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a predicted evaluation matrix 'predicted_matrix' and a dataframe 'genre_merged' containing movie ratings with separate genre columns\n",
        "\n",
        "# Get the unique genres from the dataset\n",
        "genres = genre_merged[['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']]\n",
        "\n",
        "# Create an empty list to store the recommended movies for all users\n",
        "all_users_movies = []\n",
        "\n",
        "# Iterate over each user\n",
        "for user_id in genre_merged['userId'].unique():\n",
        "    # Get the ratings given by the user\n",
        "    user_ratings = genre_merged.loc[genre_merged['userId'] == user_id, 'rating']\n",
        "\n",
        "    # Calculate the average rating for each genre\n",
        "    genre_ratings = []\n",
        "    for genre in genres.columns:\n",
        "        genre_ratings.append(np.mean(user_ratings[genres[genre] == 1]))\n",
        "\n",
        "    # Sort the genres based on average ratings\n",
        "    sorted_genres = sorted(zip(genres.columns, genre_ratings), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select the top 3 favorite genres\n",
        "    favorite_genres = [genre for genre, rating in sorted_genres[:3]]\n",
        "\n",
        "    # Select the bottom 3 unpopular genres\n",
        "    unpopular_genres = [genre for genre, rating in sorted_genres[-3:]]\n",
        "\n",
        "    # Select the row of predicted evaluations for the user\n",
        "    user_predicted_ratings = predicted_matrix[user_id - 1]\n",
        "\n",
        "    # Get the movies that the user has not rated yet and filter out movies with unpopular genres\n",
        "    unrated_movies = genre_merged[~genre_merged['movieId'].isin(genre_merged[genre_merged['userId'] == user_id]['movieId'].unique())]\n",
        "    unrated_movies = unrated_movies[~unrated_movies[favorite_genres].any(axis=1)]\n",
        "\n",
        "    # Create a new dataframe with unrated movies and their predicted ratings\n",
        "    unrated_movies_with_ratings = unrated_movies.merge(pd.DataFrame(user_predicted_ratings, columns=['predicted_rating']), left_on='movieId', right_index=True)\n",
        "\n",
        "    # Sort the unrated movies based on the predicted ratings in descending order\n",
        "    sorted_movies = unrated_movies_with_ratings.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "\n",
        "    # Remove duplicate movies\n",
        "    # Prepare the table data\n",
        "    table_data = []\n",
        "    for _, row in sorted_movies.iterrows():\n",
        "\n",
        "        movie_id = row['movieId']\n",
        "        movie_title = row['title']\n",
        "        predicted_rating = row['predicted_rating']\n",
        "        Over_view=row['Overview']\n",
        "        table_data.append([user_id, movie_id, movie_title, predicted_rating, Over_view])\n",
        "\n",
        "    # Create a DataFrame and format the columns\n",
        "    table_columns = ['userId', 'Movie ID', 'title', 'Predicted Rating', 'Overview']\n",
        "    unique_movies = pd.DataFrame(table_data, columns=table_columns).drop_duplicates(subset=['Movie ID'])\n",
        "    top_movies = unique_movies.head(25)\n",
        "    #Create a DataFrame and format the columns\n",
        "\n",
        "    table_df = pd.DataFrame(top_movies, columns=table_columns)\n",
        "\n",
        "    # Append the recommended movies for the user to the list\n",
        "    all_users_movies.append(table_df)\n",
        "\n",
        "# Print the recommended movies for all users\n",
        "for i, user_movies in enumerate(all_users_movies):\n",
        "    user_id = genre_merged['userId'].unique()[i]\n",
        "    print(f\"Recommended movies for User ID {user_id}:\")\n",
        "    print(user_movies.to_string(index=False))\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNS4rwtgIUvZ"
      },
      "outputs": [],
      "source": [
        "# Find the index of the selected user in the list\n",
        "selected_user_index = genre_merged['userId'].unique().tolist().index(selected_user_id)\n",
        "\n",
        "# Check if the selected user exists in the list\n",
        "if selected_user_index != -1:\n",
        "    # Get the recommended movies for the selected user\n",
        "    selected_user_movies = all_users_movies[selected_user_index]\n",
        "\n",
        "    # Print the recommended movies for the selected user\n",
        "    print(f\"Recommended movies for User ID {selected_user_id}:\")\n",
        "    print(selected_user_movies.to_string(index=False))\n",
        "else:\n",
        "    print(f\"No recommended movies found for User ID {selected_user_id}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSqCbYOoxA7q"
      },
      "source": [
        "### **movies from my favorite genres**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nK74htBvlrj"
      },
      "source": [
        "#### **YES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snss38Y4lB1o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a dataset dataframe 'genre_merged' containing movie ratings with separate genre columns\n",
        "\n",
        "# Get the unique genres from the dataset\n",
        "genres = genre_merged[['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']]\n",
        "\n",
        "# Define a list to store the recommendations for all users\n",
        "all_recommendations = []\n",
        "\n",
        "# Loop through each user\n",
        "for user_id in genre_merged['userId'].unique():\n",
        "    # Get the ratings given by the user\n",
        "    user_ratings = genre_merged.loc[genre_merged['userId'] == user_id, 'rating']\n",
        "\n",
        "    # Calculate the average rating for each genre\n",
        "    genre_ratings = []\n",
        "    for genre in genres.columns:\n",
        "        genre_ratings.append(np.mean(user_ratings[genres[genre] == 1]))\n",
        "\n",
        "    # Sort the genres based on average ratings\n",
        "    sorted_genres = sorted(zip(genres.columns, genre_ratings), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select the top 3 favorite genres\n",
        "    favorite_genres = [genre for genre, rating in sorted_genres[:3]]\n",
        "\n",
        "    # Select the bottom 3 unpopular genres\n",
        "    unpopular_genres = [genre for genre, rating in sorted_genres[-3:]]\n",
        "\n",
        "    # Filter the unrated movies based on the user's favorite genres\n",
        "    unrated_movies = genre_merged[~genre_merged['movieId'].isin(genre_merged[genre_merged['userId'] == user_id]['movieId'].unique())]\n",
        "    unrated_movies = unrated_movies[unrated_movies[favorite_genres].sum(axis=1) == 0]\n",
        "\n",
        "    # Create a new dataframe with unrated movies and their predicted ratings\n",
        "    unrated_movies_with_ratings = unrated_movies.merge(pd.DataFrame(user_predicted_ratings, columns=['predicted_rating']), left_on='movieId', right_index=True)\n",
        "\n",
        "    # Adjust predicted evaluations for movies of favorite genres\n",
        "    unrated_movies_with_ratings.loc[unrated_movies_with_ratings[unrated_movies_with_ratings.columns.intersection(favorite_genres)].sum(axis=1) > 0, 'predicted_rating'] *= 2\n",
        "\n",
        "    # Sort the unrated movies based on the adjusted predicted ratings in descending order\n",
        "    sorted_movies = unrated_movies_with_ratings.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "    # Remove duplicate movies\n",
        "    sorted_movies = sorted_movies.drop_duplicates(subset='movieId')\n",
        "\n",
        "    # Prepare the table data\n",
        "    table_data = []\n",
        "    for _, row in sorted_movies.iterrows():\n",
        "        movie_id = row['movieId']\n",
        "        movie_title = row['title']\n",
        "        predicted_rating = row['predicted_rating']\n",
        "        Over_view= row['Overview']\n",
        "        table_data.append([user_id, movie_id, movie_title, predicted_rating, Over_view])\n",
        "\n",
        "    # Append recommendations for the current user to the list\n",
        "    all_recommendations.extend(table_data)\n",
        "\n",
        "# Define table columns\n",
        "table_columns = ['userId', 'Movie ID', 'Title', 'Predicted Rating', 'Overview']\n",
        "\n",
        "# Create a DataFrame with all recommendations\n",
        "table_df = pd.DataFrame(all_recommendations, columns=table_columns)\n",
        "\n",
        "# Highlight predicted evaluations for each user\n",
        "table_df['Predicted Rating'] = table_df['Predicted Rating'].apply(lambda x: f\"{x:.4f}\" if x > 0 else f\"{x:.4f}\")\n",
        "\n",
        "# Print the top 25 unique recommended movies for each user\n",
        "for user_id in genre_merged['userId'].unique():\n",
        "    user_movies = table_df[table_df['userId'] == user_id].head(25)\n",
        "    print(f\"Recommendations for user {user_id}:\")\n",
        "    print(user_movies.to_string(index=False))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW0IhgDuxKr7"
      },
      "source": [
        "## **CONTENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HspGyjEtnV9K"
      },
      "outputs": [],
      "source": [
        "table_df.rename(columns={'Title': 'title'}, inplace=True)\n",
        "table_df.rename(columns={'Movie ID': 'movieId'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgGJxBSknV9K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the top 25 movies DataFrame\n",
        "top_movies = table_df\n",
        "# Load the movie details DataFrame\n",
        "movie_details = table_df\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3))\n",
        "\n",
        "# Process the data in chunks\n",
        "chunk_size = 80000\n",
        "overview_tokens = None\n",
        "\n",
        "for chunk_start in range(0, table_df.shape[0], chunk_size):\n",
        "    chunk_end = min(chunk_start + chunk_size, table_df.shape[0])\n",
        "    chunk_data = table_df.iloc[chunk_start:chunk_end]['Overview'].astype(str)\n",
        "\n",
        "    if overview_tokens is None:\n",
        "        overview_tokens = vectorizer.fit_transform(chunk_data)\n",
        "    else:\n",
        "        overview_tokens = vectorizer.transform(chunk_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBVa5RMxnV9L"
      },
      "outputs": [],
      "source": [
        "# Calculate similarity between each movie pair in batches\n",
        "batch_size = 100  # Adjust the batch size based on available memory\n",
        "num_movies = len(table_df)\n",
        "similarity_matrix = []\n",
        "\n",
        "for i in range(0, num_movies, batch_size):\n",
        "    start = i\n",
        "    end = min(i + batch_size, num_movies)\n",
        "    # Print the values of 'start' and 'end'\n",
        "    print(\"start:\", start, \"end:\", end)\n",
        "    batch_tokens = overview_tokens[start:end]\n",
        "    if batch_tokens.shape[0] == 0:\n",
        "        continue\n",
        "    print(\"Shape of batch_tokens:\", batch_tokens.shape)\n",
        "    batch_similarity = cosine_similarity(batch_tokens, overview_tokens)\n",
        "    similarity_matrix.append(batch_similarity)\n",
        "\n",
        "# Concatenate the similarity matrices from each batch\n",
        "similarity_matrix = np.concatenate(similarity_matrix, axis=0)\n",
        "print(\"Shape of similarity_matrix:\", similarity_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRzsLow_nV9M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "result_df = pd.DataFrame(columns=['Name of movie', 'Predicted Rating', 'Evaluation Similarity'])\n",
        "\n",
        "# Set the number of similar movies to include in the result\n",
        "num_similar_movies = 25\n",
        "\n",
        "# Check the dimensions of the similarity matrix\n",
        "num_movies = similarity_matrix.shape[0]\n",
        "\n",
        "# Iterate over each movie in the subset\n",
        "for movie in table_df.itertuples():\n",
        "    movie_title = movie.title\n",
        "    movie_index = movie.Index  # Assuming 'Index' represents the movie index in the similarity matrix\n",
        "\n",
        "    # Check if the movie index is within the bounds of the similarity matrix\n",
        "    if movie_index >= num_movies:\n",
        "        continue\n",
        "\n",
        "    predicted_rating = movie._4  # Assuming the 'Predicted Rating' column is at index 4\n",
        "\n",
        "    # Get the row of the similarity matrix corresponding to the current movie\n",
        "    similarity_scores = similarity_matrix[movie_index]\n",
        "\n",
        "    # Find the indices of the top similar movies (excluding the current movie itself)\n",
        "    top_indices = similarity_scores.argsort()[:-num_similar_movies-1:-1]\n",
        "\n",
        "    # Get the movie names and similarity scores for the top similar movies\n",
        "    similar_movies = table_df.loc[top_indices, ['title', 'Predicted Rating']]\n",
        "    similar_movies['Evaluation Similarity'] = similarity_scores[top_indices]\n",
        "\n",
        "    # Append the current movie's details to the result DataFrame\n",
        "    result_df = pd.concat([result_df, pd.DataFrame({'Name of movie': [movie_title],\n",
        "                                                    'Predicted Rating': [predicted_rating],\n",
        "                                                    'Evaluation Similarity': ['']})], ignore_index=True)\n",
        "\n",
        "    # Append the similar movies' details to the result DataFrame\n",
        "    result_df = pd.concat([result_df, similar_movies], ignore_index=True)\n",
        "\n",
        "# Write the result DataFrame to a CSV file\n",
        "result_df.head(25).to_csv('result-1002.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRoQ5LuBnV9O"
      },
      "outputs": [],
      "source": [
        "average_ratings = merged_dataset.groupby('title')['rating'].mean().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5Hj4NwznV9O"
      },
      "outputs": [],
      "source": [
        "average_ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1zeoPeQnV9P"
      },
      "outputs": [],
      "source": [
        "filtered_df = merged_dataset[(merged_dataset['rating'] >= 0) & (merged_dataset['rating'] <= 350)]\n",
        "\n",
        "# Count the total number of movie ratings within the interval\n",
        "num_Rating = filtered_df['title'].value_counts().reset_index()\n",
        "\n",
        "# Rename the columns\n",
        "num_Rating.columns = ['title', 'Number of ratings']\n",
        "\n",
        "num_Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay5PEwSsnV9Q"
      },
      "outputs": [],
      "source": [
        "merged_df1 = pd.merge(num_Rating, average_ratings, on='title')\n",
        "merged_df1=merged_df1.rename(columns={'rating': 'avg_rating'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6aORK3anV9a"
      },
      "outputs": [],
      "source": [
        "merged_df2 = pd.merge(result_df, merged_df1, on='title', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjJbjSPInV9b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Sort by evaluation similarity in descending order\n",
        "merged_df3 = merged_df2.sort_values(by='Evaluation Similarity', ascending=False)\n",
        "\n",
        "# Select the top 25 rows\n",
        "merged_df3 = merged_df2.drop_duplicates(subset='title').head(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSQG65nRnV9c"
      },
      "outputs": [],
      "source": [
        "merged_df3  = merged_df3.drop('Name of movie', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThtbTy6-nV9c"
      },
      "outputs": [],
      "source": [
        "desired_columns = ['title', 'Predicted Rating', 'Evaluation Similarity', 'avg_rating', 'Number of ratings']  # Specify the order of columns\n",
        "\n",
        "# Reindex the columns of the DataFrame\n",
        "merged_df3 = merged_df3.reindex(columns=desired_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a09bWjm2nV9d"
      },
      "outputs": [],
      "source": [
        "merged_df3['Evaluation Similarity'] = merged_df3['Number of ratings'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKRe8QwynV9g"
      },
      "source": [
        "EXPERT SYSTEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soZGsi64nV9i"
      },
      "outputs": [],
      "source": [
        "merged_df3['Predicted Rating'] = merged_df3['Predicted Rating'] .astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZr89JZ6nV9j"
      },
      "outputs": [],
      "source": [
        "import skfuzzy as fuzz\n",
        "from skfuzzy import control as ctrl\n",
        "\n",
        "# Create Antecedent and Consequent objects for the linguistic variables\n",
        "inp1 = ctrl.Antecedent(np.arange(0, 5.1, 0.1), 'inp1')\n",
        "inp2 = ctrl.Antecedent(np.arange(0, 351, 1), 'inp2')\n",
        "inp3 = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'inp3')\n",
        "\n",
        "importance = ctrl.Consequent(np.arange(0, 1.1, 0.1), 'importance')\n",
        "importance['low'] = fuzz.trimf(importance.universe, [0, 0, 0.25])\n",
        "importance['very low'] = fuzz.trimf(importance.universe, [0, 0.1, 0.3])\n",
        "importance['medium'] = fuzz.trimf(importance.universe, [0.2, 0.4, 0.6])\n",
        "importance['high'] = fuzz.trimf(importance.universe, [0.5, 0.7, 0.9])\n",
        "importance['very high'] = fuzz.trimf(importance.universe, [0.75, 1, 1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the membership functions for the linguistic variables\n",
        "# Example membership functions for input variables\n",
        "\n",
        "inp1['low'] = fuzz.trimf(inp1.universe, [0, 0, 2])\n",
        "inp1['medium'] = fuzz.trimf(inp1.universe, [1, 2, 3])\n",
        "inp1['high'] = fuzz.trimf(inp1.universe, [2, 4, 5])\n",
        "\n",
        "\n",
        "\n",
        "# Define membership functions for other input variables (inp2, inp3) and the output variable (importance)\n",
        "\n",
        "inp2['few'] = fuzz.trimf(inp2.universe, [0, 0, 100])\n",
        "inp2['medium'] = fuzz.trimf(inp2.universe, [50, 150, 250])\n",
        "inp2['much'] = fuzz.trimf(inp2.universe, [150, 250, 350])\n",
        "inp2['very much'] = fuzz.trimf(inp2.universe, [250, 350, 350])\n",
        "\n",
        "\n",
        "inp3['low'] = fuzz.trimf(inp3.universe, [0, 0, 0.25])\n",
        "inp3['medium'] = fuzz.trimf(inp3.universe, [0.1, 0.4, 0.7])\n",
        "inp3['high'] = fuzz.trimf(inp3.universe, [0.4, 0.7, 0.9])\n",
        "inp3['very high'] = fuzz.trimf(inp3.universe, [0.75, 1, 1])\n",
        "\n",
        "\n",
        "# Define the fuzzy rules\n",
        "rule1 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['low'], importance['very low'])\n",
        "rule2 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['medium'], importance['very low'])\n",
        "rule3 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['high'], importance['very low'])\n",
        "rule4 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['very high'], importance['low'])\n",
        "rule5 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['low'], importance['very low'])\n",
        "rule6 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['medium'], importance['very low'])\n",
        "rule7 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['high'], importance['very low'])\n",
        "rule8 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['very high'], importance['very low'])\n",
        "rule9 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['low'], importance['very low'])\n",
        "rule10 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['medium'], importance['very low'])\n",
        "rule11 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['high'], importance['very low'])\n",
        "rule12 = ctrl.Rule(inp1['low'] & inp2['few'] & inp3['very high'], importance['very low'])\n",
        "rule13 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['low'], importance['very low'])\n",
        "rule14 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['medium'], importance['very low'])\n",
        "rule15 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['high'], importance['very low'])\n",
        "rule16 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['very high'], importance['very low'])\n",
        "rule17 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['low'], importance['very low'])\n",
        "rule18 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['medium'], importance['very low'])\n",
        "rule19 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['high'], importance['very low'])\n",
        "rule20 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['very high'], importance['very low'])\n",
        "rule21 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['low'], importance['very low'])\n",
        "rule22 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['medium'], importance['very low'])\n",
        "rule23 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['high'], importance['very low'])\n",
        "rule24 = ctrl.Rule(inp1['low'] & inp2['medium'] & inp3['very high'], importance['very low'])\n",
        "rule25 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['low'], importance['very low'])\n",
        "rule26 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['medium'], importance['very low'])\n",
        "rule27 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['high'], importance['very low'])\n",
        "rule28 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['very high'], importance['very low'])\n",
        "rule29 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['low'], importance['very low'])\n",
        "rule30 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['medium'], importance['very low'])\n",
        "rule31 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['high'], importance['very low'])\n",
        "rule32 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['very high'], importance['very low'])\n",
        "rule33 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['low'], importance['very low'])\n",
        "rule34 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['medium'], importance['very low'])\n",
        "rule35 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['high'], importance['very low'])\n",
        "rule36 = ctrl.Rule(inp1['low'] & inp2['much'] & inp3['very high'], importance['very low'])\n",
        "rule37 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['low'], importance['very low'])\n",
        "rule38 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['medium'], importance['very low'])\n",
        "rule39 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['high'], importance['very low'])\n",
        "rule40 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['very high'], importance['very low'])\n",
        "rule41 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['low'], importance['very low'])\n",
        "rule42 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['medium'], importance['very low'])\n",
        "rule43 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['high'], importance['very low'])\n",
        "rule44 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['very high'], importance['very low'])\n",
        "rule45 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['low'], importance['very low'])\n",
        "rule46 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['medium'], importance['very low'])\n",
        "rule47 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['high'], importance['very low'])\n",
        "rule48 = ctrl.Rule(inp1['low'] & inp2['very much'] & inp3['very high'], importance['very low'])\n",
        "rule49 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['low'], importance['low'])\n",
        "rule50 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['medium'], importance['low'])\n",
        "rule51 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['high'], importance['low'])\n",
        "rule52 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['very high'], importance['medium'])\n",
        "rule53 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['low'], importance['very low'])\n",
        "rule54 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['medium'], importance['very low'])\n",
        "rule55 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['high'], importance['very low'])\n",
        "rule56 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['very high'], importance['low'])\n",
        "rule57 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['low'], importance['very low'])\n",
        "rule58 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['medium'], importance['very low'])\n",
        "rule59 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['high'], importance['very low'])\n",
        "rule60 = ctrl.Rule(inp1['medium'] & inp2['few'] & inp3['very high'], importance['low'])\n",
        "rule61 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['low'], importance['low'])\n",
        "rule62 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['medium'], importance['medium'])\n",
        "rule63 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['high'], importance['medium'])\n",
        "rule64 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['very high'], importance['medium'])\n",
        "rule65 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['low'], importance['low'])\n",
        "rule66 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['medium'], importance['low'])\n",
        "rule67 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['high'], importance['low'])\n",
        "rule68 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['very high'], importance['medium'])\n",
        "rule69 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['low'], importance['low'])\n",
        "rule70 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['medium'], importance['low'])\n",
        "rule71 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['high'], importance['low'])\n",
        "rule72 = ctrl.Rule(inp1['medium'] & inp2['medium'] & inp3['very high'], importance['low'])\n",
        "rule73 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['low'], importance['medium'])\n",
        "rule74 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['medium'], importance['medium'])\n",
        "rule75 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['high'], importance['medium'])\n",
        "rule76 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['very high'], importance['medium'])\n",
        "rule77 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['low'], importance['low'])\n",
        "rule78 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['medium'], importance['low'])\n",
        "rule79 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['high'], importance['medium'])\n",
        "rule80 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['very high'], importance['medium'])\n",
        "rule81 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['low'], importance['low'])\n",
        "rule82 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['medium'], importance['low'])\n",
        "rule83 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['high'], importance['low'])\n",
        "rule84 = ctrl.Rule(inp1['medium'] & inp2['much'] & inp3['very high'], importance['medium'])\n",
        "rule85 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['low'], importance['medium'])\n",
        "rule86 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['medium'], importance['medium'])\n",
        "rule87 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['high'], importance['medium'])\n",
        "rule88 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['very high'], importance['medium'])\n",
        "rule89 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['low'], importance['low'])\n",
        "rule90 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['medium'], importance['medium'])\n",
        "rule91 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['high'], importance['medium'])\n",
        "rule92 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['very high'], importance['medium'])\n",
        "rule93 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['low'], importance['low'])\n",
        "rule94 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['medium'], importance['low'])\n",
        "rule95 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['high'], importance['medium'])\n",
        "rule96 = ctrl.Rule(inp1['medium'] & inp2['very much'] & inp3['very high'], importance['medium'])\n",
        "rule97 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['low'], importance['low'])\n",
        "rule98 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['medium'], importance['low'])\n",
        "rule99 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['high'], importance['medium'])\n",
        "rule100 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['very high'], importance['high'])\n",
        "rule101 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['low'], importance['low'])\n",
        "rule102 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['medium'], importance['low'])\n",
        "rule103 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['high'], importance['medium'])\n",
        "rule104 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['very high'], importance['medium'])\n",
        "rule105 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['low'], importance['low'])\n",
        "rule106 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['medium'], importance['low'])\n",
        "rule107 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['high'], importance['low'])\n",
        "rule108 = ctrl.Rule(inp1['high'] & inp2['few'] & inp3['very high'], importance['medium'])\n",
        "rule109 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['low'], importance['medium'])\n",
        "rule110 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['medium'], importance['medium'])\n",
        "rule111 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['high'], importance['high'])\n",
        "rule112 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['very high'], importance['high'])\n",
        "rule113 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['low'], importance['medium'])\n",
        "rule114 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['medium'], importance['medium'])\n",
        "rule115 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['high'], importance['medium'])\n",
        "rule116 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['very high'], importance['high'])\n",
        "rule117 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['low'], importance['medium'])\n",
        "rule118 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['medium'], importance['medium'])\n",
        "rule119 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['high'], importance['medium'])\n",
        "rule120 = ctrl.Rule(inp1['high'] & inp2['medium'] & inp3['very high'], importance['medium'])\n",
        "rule121 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['low'], importance['medium'])\n",
        "rule122 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['medium'], importance['high'])\n",
        "rule123 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['high'], importance['high'])\n",
        "rule124 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['very high'], importance['very high'])\n",
        "rule125 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['low'], importance['medium'])\n",
        "rule126 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['medium'], importance['medium'])\n",
        "rule127 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['high'], importance['high'])\n",
        "rule128 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['very high'], importance['high'])\n",
        "rule129 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['low'], importance['medium'])\n",
        "rule130 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['medium'], importance['medium'])\n",
        "rule131 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['high'], importance['medium'])\n",
        "rule132 = ctrl.Rule(inp1['high'] & inp2['much'] & inp3['very high'], importance['high'])\n",
        "rule133 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['low'], importance['high'])\n",
        "rule134 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['medium'], importance['high'])\n",
        "rule135 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['high'], importance['very high'])\n",
        "rule136 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['very high'], importance['very high'])\n",
        "rule137 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['low'], importance['high'])\n",
        "rule138 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['medium'], importance['high'])\n",
        "rule139 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['high'], importance['high'])\n",
        "rule140 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['very high'], importance['very high'])\n",
        "rule141 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['low'], importance['medium'])\n",
        "rule142 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['medium'], importance['high'])\n",
        "rule143 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['high'], importance['high'])\n",
        "rule144 = ctrl.Rule(inp1['high'] & inp2['very much'] & inp3['very high'], importance['high'])\n",
        "# Define the control system\n",
        "system = ctrl.ControlSystem([\n",
        "rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9, rule10,\n",
        "rule11, rule12, rule13, rule14, rule15, rule16, rule17, rule18, rule19, rule20,\n",
        "rule21, rule22, rule23, rule24, rule25, rule26, rule27, rule28, rule29, rule30,\n",
        "rule31, rule32, rule33, rule34, rule35, rule36, rule37, rule38, rule39, rule40,\n",
        "rule41, rule42, rule43, rule44, rule45, rule46, rule47, rule48, rule49, rule50,\n",
        "rule51, rule52, rule53, rule54, rule55, rule56, rule57, rule58, rule59, rule60,\n",
        "rule61, rule62, rule63, rule64, rule65, rule66, rule67, rule68, rule69, rule70,\n",
        "rule71, rule72, rule73, rule74, rule75, rule76, rule77, rule78, rule79, rule80,\n",
        "rule81, rule82, rule83, rule84, rule85, rule86, rule87, rule88, rule89, rule90,\n",
        "rule91, rule92, rule93, rule94, rule95, rule96, rule97, rule98, rule99, rule100,\n",
        "rule101, rule102, rule103, rule104, rule105, rule106, rule107, rule108, rule109, rule110,\n",
        "rule111, rule112, rule113, rule114, rule115, rule116, rule117, rule118, rule119, rule120,\n",
        "rule121, rule122, rule123, rule124, rule125, rule126, rule127, rule128, rule129, rule130,\n",
        "rule131, rule132, rule133, rule134, rule135, rule136, rule137, rule138, rule139, rule140,\n",
        "rule141, rule142, rule143, rule144\n",
        "])\n",
        "\n",
        "\n",
        "# Define the control system simulation\n",
        "#imp_sim = ctrl.ControlSystemSimulation(imp_ctrl)\n",
        "\n",
        "# Pass inputs to the ControlSystemSimulation\n",
        "#imp_sim.input['inp1'] = merged_df3['avg_rating'].values\n",
        "#imp_sim.input['inp2'] = merged_df3['Number of ratings'].values\n",
        "#imp_sim.input['inp3'] = merged_df3['Evaluation Similarity'].values\n",
        "\n",
        "# Crunch the numbers\n",
        "#imp_sim.compute()\n",
        "\n",
        "# Retrieve the output\n",
        "#output = imp_sim.output['importance']\n",
        "\n",
        "expert_system = ctrl.ControlSystemSimulation(system)\n",
        "\n",
        "# Iterate over the rows of merged_df\n",
        "for index, row in merged_df3.iterrows():\n",
        "    # Set the input values\n",
        "    expert_system.input['inp1'] = row['avg_rating']\n",
        "    expert_system.input['inp2'] = row['Number of ratings']\n",
        "    expert_system.input['inp3'] = row['Evaluation Similarity']\n",
        "\n",
        "    # Compute the output value\n",
        "    expert_system.compute()\n",
        "\n",
        "    # Get the output value\n",
        "    importance_value = expert_system.output['importance']\n",
        "\n",
        "    # Calculate the final evaluation based on EXS IMPORTANCE and predicted evaluation\n",
        "    predicted_evaluation = row['Predicted Rating']\n",
        "\n",
        "    # Check if the predicted evaluation is a valid numerical value\n",
        "    if pd.notnull(predicted_evaluation):\n",
        "        # Calculate the final evaluation based on EXS IMPORTANCE and predicted evaluation\n",
        "        if predicted_evaluation <= 0:\n",
        "            final_evaluation = predicted_evaluation * row['EXS IMPORTANCE']\n",
        "        else:\n",
        "            final_evaluation = predicted_evaluation * (1 + row['EXS IMPORTANCE'])\n",
        "    else:\n",
        "        # Handle cases where the predicted evaluation is not a valid numerical value\n",
        "        final_evaluation = 0\n",
        "\n",
        "    # Update the 'Final Evaluation' column in merged_df\n",
        "    merged_df3.loc[index, 'Final Evaluation'] = final_evaluation\n",
        "\n",
        "# Sort the DataFrame by 'Final Evaluation' column in descending order\n",
        "merged_df4 = merged_df3.sort_values(by='Final Evaluation', ascending=False)\n",
        "\n",
        "# Select the top 25 movies with the highest 'Final Evaluation' values\n",
        "top_25_movies_F = merged_df4.head(25)\n",
        "\n",
        "# Print the top 25 movies with their corresponding 'Final Evaluation' values\n",
        "print(top_25_movies_F[['title', 'Predicted Rating','EXS IMPORTANCE','Final Evaluation']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCaBj-0cnV9l"
      },
      "outputs": [],
      "source": [
        "top_25_movies_F"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_V4YWrxoBDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}